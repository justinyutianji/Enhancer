{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import sys\n",
    "import os\n",
    "# Get the parent directory of train/Synthetic_Data_Generator\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), \"../../\"))\n",
    "sys.path.append(parent_dir)\n",
    "from train.utils import EnhancerDataset\n",
    "from train import interpretation\n",
    "from model.model import ExplaiNN3\n",
    "from scripts.synthetic_prediction import generate_synthetic_distance_data, motif_score_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Synthetic Data and Test Motif Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cnns = 90\n",
    "filter_size = 19\n",
    "batch = 322\n",
    "weight_file = '/pmglocal/ty2514/Enhancer/Enhancer/data/ExplaiNN_both_results/best_r2_model_epoch_53.pth'\n",
    "target_labels = ['GFP+','GFP-']\n",
    "meme_file_dir = '/pmglocal/ty2514/Enhancer/motif-clustering/results/all.db.meme'\n",
    "output_pickle_file = '/pmglocal/ty2514/Enhancer/Enhancer/train/Synthetic_Data_Generator/synthetic_seq_dist.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explainn loaded on CPU\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize the model without moving it to the device yet\n",
    "explainn = ExplaiNN3(num_cnns=num_cnns, input_length=608, num_classes=2,\n",
    "                     filter_size=filter_size, num_fc=2, pool_size=7, pool_stride=7,\n",
    "                     drop_out=0.3, weight_path=None)  # Training\n",
    "\n",
    "# Load the model weights conditionally based on GPU availability\n",
    "if torch.cuda.is_available():\n",
    "    explainn.load_state_dict(torch.load(weight_file))\n",
    "    print('explainn loaded on GPU')\n",
    "else:\n",
    "    explainn.load_state_dict(torch.load(weight_file, map_location=torch.device('cpu')))\n",
    "    print('explainn loaded on CPU')\n",
    "# Move the model to the appropriate device after loading the weights\n",
    "explainn.to(device)\n",
    "explainn.eval()\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PWM for M00224_2.00 has length: 8\n",
      "M00224_2.00: CCCGCCCC\n",
      "PWM for M00303_2.00 has length: 11\n",
      "M00303_2.00: GCTAATTACTG\n",
      "\n",
      "\n",
      "Motif A CCCGCCCC has 20 200nt DNA segments, inserted with distance 10\n",
      "Motif B GCTAATTACTG has 19 200nt DNA segments, inserted with distance 10\n",
      "Motif A CCCGCCCC has 20 200nt DNA segments, inserted with distance 10\n",
      "Motif B GCTAATTACTG has 19 200nt DNA segments, inserted with distance 10\n",
      "Motif A CCCGCCCC has 20 200nt DNA segments, inserted with distance 10\n",
      "Motif B GCTAATTACTG has 19 200nt DNA segments, inserted with distance 10\n",
      "Motif A CCCGCCCC has 20 200nt DNA segments, inserted with distance 10\n",
      "Motif B GCTAATTACTG has 19 200nt DNA segments, inserted with distance 10\n",
      "Motif A CCCGCCCC has 20 200nt DNA segments, inserted with distance 10\n",
      "Motif B GCTAATTACTG has 19 200nt DNA segments, inserted with distance 10\n"
     ]
    }
   ],
   "source": [
    "df = generate_synthetic_distance_data(200, ['M00224_2.00','M00303_2.00'],meme_file_dir,output_pickle_file,distance = 10, replicate=5,save_plot = False)\n",
    "result_df = motif_score_prediction(model = explainn, df = df, device = device, batch = batch, target_labels=target_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filter</th>\n",
       "      <th>cluster</th>\n",
       "      <th>tf_name</th>\n",
       "      <th>family_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>filter2</td>\n",
       "      <td>AC0069</td>\n",
       "      <td>Pax4</td>\n",
       "      <td>['Paired box factors']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>filter6</td>\n",
       "      <td>AC0069</td>\n",
       "      <td>Pax4</td>\n",
       "      <td>['Paired box factors']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>filter7</td>\n",
       "      <td>AC0066</td>\n",
       "      <td>Gli1/Gli2</td>\n",
       "      <td>['C2H2 zinc finger factors']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>filter8</td>\n",
       "      <td>AC0069</td>\n",
       "      <td>Pax4</td>\n",
       "      <td>['Paired box factors']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>filter10</td>\n",
       "      <td>AC0069</td>\n",
       "      <td>Pax4</td>\n",
       "      <td>['Paired box factors']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     filter cluster    tf_name                   family_name\n",
       "0   filter2  AC0069       Pax4        ['Paired box factors']\n",
       "1   filter6  AC0069       Pax4        ['Paired box factors']\n",
       "2   filter7  AC0066  Gli1/Gli2  ['C2H2 zinc finger factors']\n",
       "3   filter8  AC0069       Pax4        ['Paired box factors']\n",
       "4  filter10  AC0069       Pax4        ['Paired box factors']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_results = pd.read_csv(\"/pmglocal/ty2514/Enhancer/motif-clustering/JASPAR2024_mus_musculus_non-redundant_results/metadata.tsv\",\n",
    "                                        sep=\"\\t\",comment=\"#\")\n",
    "tomtom_results = pd.read_csv(\"/pmglocal/ty2514/Enhancer/Enhancer/data/ExplaiNN_both_results/tomtom_results/tomtom.tsv\",\n",
    "                                        sep=\"\\t\",comment=\"#\")\n",
    "filters_with_min_q = tomtom_results.groupby('Query_ID').min()[\"q-value\"]\n",
    "tomtom_results = tomtom_results[[\"Target_ID\", \"Query_ID\", \"q-value\"]]\n",
    "tomtom_results = tomtom_results[tomtom_results[\"q-value\"]<0.05]\n",
    "\n",
    "motif_to_cluster = cluster_results.set_index('motif_id')['cluster'].to_dict()\n",
    "motif_to_tf_name = cluster_results.set_index('motif_id')['tf_name'].to_dict()\n",
    "motif_to_family_name = cluster_results.set_index('motif_id')['family_name'].to_dict()\n",
    "filters = tomtom_results[\"Query_ID\"].unique()\n",
    "\n",
    "# Assuming `annotation` is already populated\n",
    "annotation_data = []\n",
    "\n",
    "for f in filters:\n",
    "    t = tomtom_results[tomtom_results[\"Query_ID\"] == f]\n",
    "    target_id = t[\"Target_ID\"]\n",
    "\n",
    "    if len(target_id) > 5:\n",
    "        target_id = target_id[:5]\n",
    "\n",
    "    # Join Unique annotations by '/'\n",
    "    cluster = \"/\".join({motif_to_cluster[i]: i for i in target_id.values})\n",
    "    tf_name = \"/\".join({motif_to_tf_name[i]: i for i in target_id.values})\n",
    "    family_name = \"/\".join({motif_to_family_name[i]: i for i in target_id.values})\n",
    "\n",
    "    # Append the data to the list\n",
    "    annotation_data.append({\n",
    "        'filter': f,\n",
    "        'cluster': cluster,\n",
    "        'tf_name': tf_name,\n",
    "        'family_name': family_name\n",
    "    })\n",
    "\n",
    "# Create a DataFrame from the collected data\n",
    "annotation_df = pd.DataFrame(annotation_data)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "annotation_df.iloc[:5,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_df has shape: (2, 90) (number of labels, number of fileters)\n",
      "['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69', 'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76', 'f77', 'f78', 'f79', 'f80', 'f81', 'f82', 'f83', 'f84', 'f85', 'f86', 'f87', 'f88', 'f89']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>AC0069(Pax4)-f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>AC0069(Pax4)-f6</th>\n",
       "      <th>AC0066(Gli1/Gli2)-f7</th>\n",
       "      <th>AC0069(Pax4)-f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f80</th>\n",
       "      <th>f81</th>\n",
       "      <th>f82</th>\n",
       "      <th>f83</th>\n",
       "      <th>AC0069(Pax4)-f84</th>\n",
       "      <th>f85</th>\n",
       "      <th>f86</th>\n",
       "      <th>f87</th>\n",
       "      <th>AC0069(Pax4)-f88</th>\n",
       "      <th>f89</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GFP+</th>\n",
       "      <td>0.081534</td>\n",
       "      <td>0.181157</td>\n",
       "      <td>0.248874</td>\n",
       "      <td>0.181560</td>\n",
       "      <td>0.002539</td>\n",
       "      <td>0.047324</td>\n",
       "      <td>0.237871</td>\n",
       "      <td>0.110817</td>\n",
       "      <td>0.233839</td>\n",
       "      <td>0.033559</td>\n",
       "      <td>...</td>\n",
       "      <td>0.212228</td>\n",
       "      <td>0.115420</td>\n",
       "      <td>0.157949</td>\n",
       "      <td>0.121214</td>\n",
       "      <td>0.217157</td>\n",
       "      <td>0.134688</td>\n",
       "      <td>0.163591</td>\n",
       "      <td>0.001927</td>\n",
       "      <td>0.169545</td>\n",
       "      <td>-0.001799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFP-</th>\n",
       "      <td>0.000444</td>\n",
       "      <td>0.083332</td>\n",
       "      <td>0.188044</td>\n",
       "      <td>0.242838</td>\n",
       "      <td>0.058648</td>\n",
       "      <td>0.123694</td>\n",
       "      <td>0.170986</td>\n",
       "      <td>0.155349</td>\n",
       "      <td>0.080560</td>\n",
       "      <td>0.121754</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099247</td>\n",
       "      <td>0.197698</td>\n",
       "      <td>0.133829</td>\n",
       "      <td>0.035363</td>\n",
       "      <td>0.230519</td>\n",
       "      <td>0.041809</td>\n",
       "      <td>0.102332</td>\n",
       "      <td>0.035025</td>\n",
       "      <td>0.165388</td>\n",
       "      <td>-0.024118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            f0        f1  AC0069(Pax4)-f2        f3        f4        f5  \\\n",
       "GFP+  0.081534  0.181157         0.248874  0.181560  0.002539  0.047324   \n",
       "GFP-  0.000444  0.083332         0.188044  0.242838  0.058648  0.123694   \n",
       "\n",
       "      AC0069(Pax4)-f6  AC0066(Gli1/Gli2)-f7  AC0069(Pax4)-f8        f9  ...  \\\n",
       "GFP+         0.237871              0.110817         0.233839  0.033559  ...   \n",
       "GFP-         0.170986              0.155349         0.080560  0.121754  ...   \n",
       "\n",
       "           f80       f81       f82       f83  AC0069(Pax4)-f84       f85  \\\n",
       "GFP+  0.212228  0.115420  0.157949  0.121214          0.217157  0.134688   \n",
       "GFP-  0.099247  0.197698  0.133829  0.035363          0.230519  0.041809   \n",
       "\n",
       "           f86       f87  AC0069(Pax4)-f88       f89  \n",
       "GFP+  0.163591  0.001927          0.169545 -0.001799  \n",
       "GFP-  0.102332  0.035025          0.165388 -0.024118  \n",
       "\n",
       "[2 rows x 90 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = explainn.final.weight.detach().cpu().numpy()\n",
    "print(f'weight_df has shape: {weights.shape} (number of labels, number of fileters)')\n",
    "filters = [\"f\"+str(i) for i in range(num_cnns)]\n",
    "print(filters)\n",
    "for index,row in annotation_df.iterrows():\n",
    "    filter = row['filter']\n",
    "    split_string = filter.split('filter', 1)\n",
    "    # change 'filter{i}' to 'f{i}'. e.g. filter20 -> f20\n",
    "    new_filter_name = 'f' + split_string[1].strip()\n",
    "    # Check if filter is in the filters list\n",
    "    if new_filter_name in filters:\n",
    "        # Find the index of the element to be replaced\n",
    "        index_to_replace = filters.index(new_filter_name)\n",
    "        # Replace the element in the filters list\n",
    "        filters[index_to_replace] = f\"{row['cluster']}({row['tf_name']})-{new_filter_name}\"\n",
    "\n",
    "\n",
    "#for i in annotation.keys():\n",
    "#    filters[int(i.split(\"filter\")[-1])] = annotation[i]\n",
    "weight_df = pd.DataFrame(weights, target_labels, columns=filters)\n",
    "#result_dir = '/pmglocal/ty2514/Enhancer/Enhancer/data/ExplaiNN_both_results'\n",
    "#weight_file_dir = os.path.join(result_dir, 'filter_weights.csv')\n",
    "# Save the DataFrame to a CSV file\n",
    "#weight_df.to_csv(weight_file_dir, index=True)  # Set index=True if you want to save the index\n",
    "weight_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "def plot_filter_weight(weight_df, dir_save_plot):\n",
    "    num_cnns = weight_df.shape[1]  # Assuming number of columns represents CNNs\n",
    "    \n",
    "    # Loop through each row to create a separate plot\n",
    "    for index, row in weight_df.iterrows():\n",
    "        # Sort the row in descending order by weight values\n",
    "        sorted_row = row.sort_values(ascending=False)\n",
    "\n",
    "        # Extract labels (column names, now sorted) and values (sorted weights)\n",
    "        labels = sorted_row.index\n",
    "        values = sorted_row.values\n",
    "\n",
    "        # Calculate min and max values for the x-axis range\n",
    "        min_value = values.min()\n",
    "        max_value = values.max()\n",
    "\n",
    "        # Define colors for the bars based on a condition (customize as needed)\n",
    "        colors = ['royalblue' if '-' not in label.lower() else 'red' for label in labels]\n",
    "\n",
    "        # Create a new figure for each row\n",
    "        plt.figure(figsize=(8, math.ceil(0.15 * num_cnns)))\n",
    "\n",
    "        # Plot the bar chart for this row\n",
    "        plt.barh(labels, values, color=colors)\n",
    "        plt.title(f'Weights for Target: {index}')\n",
    "        plt.xlabel('Weight')\n",
    "        plt.ylabel('Filters')\n",
    "\n",
    "        # Invert y-axis to have the highest value at the top\n",
    "        plt.gca().invert_yaxis()\n",
    "\n",
    "        # Set x-axis limits\n",
    "        plt.xlim(min_value - 0.05, max_value + 0.05)\n",
    "\n",
    "        # Annotate the value next to each bar\n",
    "        for i, (label, value) in enumerate(zip(labels, values)):\n",
    "            if value >= 0:\n",
    "                plt.text(value, i, f'{value:.3f}', va='center', ha='left', fontsize=10)\n",
    "            else:\n",
    "                plt.text(value, i, f'{value:.3f}', va='center', ha='right', fontsize=10)\n",
    "\n",
    "        # Adjust layout to prevent overlap\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Save the individual plot to the specified directory\n",
    "        plot_filename = f'{dir_save_plot}/filter_weights_{index}.png'\n",
    "        # plt.savefig(plot_filename)\n",
    "        print(f'Saved plot for {index} at {plot_filename}')\n",
    "\n",
    "        # Optionally close the plot after saving to free up memory\n",
    "        # plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "#plot_filter_weight(weight_df,'asdf')\n",
    "annotated_weight_df = weight_df.loc[:, weight_df.columns.str.contains('-')]\n",
    "#plot_filter_weight(annotated_weight_df,'asdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Bound = 0.25 as a cutoff to select high confident predictions.\n",
      "Total number of input samples: 28800\n",
      "torch.Size([21449, 4, 608])\n",
      "torch.Size([21449, 2])\n",
      "Number of input samples with high confident prediction: 21449\n"
     ]
    }
   ],
   "source": [
    "upper_bound = 0.25\n",
    "input_data_dir = '/pmglocal/ty2514/Enhancer/Enhancer/data/input_data.csv'\n",
    "df = pd.read_csv(input_data_dir)\n",
    "dataset = EnhancerDataset(df, feature_list=['G+','G-'], scale_mode = 'none')\n",
    "# Prepare dataloader\n",
    "dataset = DataLoader(dataset=dataset, batch_size=batch, shuffle=False)\n",
    "# Running get_explainn_predictions function to get predictions and true labels for all sequences in the given data loader\n",
    "predictions, labels = interpretation.get_explainn_predictions(dataset, explainn, device, isSigmoid=False)\n",
    "\n",
    "# Calculate absolute residuals\n",
    "residuals = np.abs(labels - predictions)\n",
    "\n",
    "# Define the upper bound of residuals\n",
    "print(f'Using Bound = {upper_bound} as a cutoff to select high confident predictions.')\n",
    "\n",
    "# Create a mask for filtering out samples with low confident precition (abs(residual) > upper_bound)\n",
    "mask = (residuals <= upper_bound).all(axis=1)\n",
    "# Get sequences and labels from dataset\n",
    "data_inp = []\n",
    "data_out = []\n",
    "# Iterate over the DataLoader\n",
    "for batch_features, batch_labels in dataset:\n",
    "    data_inp.append(batch_features)\n",
    "    data_out.append(batch_labels)\n",
    "# Concatenate all the batches into single tensors\n",
    "data_inp = torch.cat(data_inp, dim=0)\n",
    "data_out = torch.cat(data_out, dim=0)\n",
    "\n",
    "# Use the mask to filter the predictions and labels\n",
    "print(f'Total number of input samples: {len(data_inp)}')\n",
    "data_inp = data_inp[mask]\n",
    "data_out = data_out[mask]\n",
    "print(data_inp.shape)\n",
    "print(data_out.shape)\n",
    "\n",
    "print(f'Number of input samples with high confident prediction: {len(data_inp)}')\n",
    "\n",
    "# Create new dataloader with filtered high confident samples\n",
    "dataset = torch.utils.data.TensorDataset(data_inp, data_out)\n",
    "data_loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                          batch_size=batch, shuffle=False,)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(unit_index)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Calculate unit importance for the current unit\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m unit_outputs \u001b[38;5;241m=\u001b[39m \u001b[43minterpretation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_explainn_unit_outputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexplainn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m target_labels \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGFP+\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGFP-\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     14\u001b[0m importance \u001b[38;5;241m=\u001b[39m interpretation\u001b[38;5;241m.\u001b[39mget_specific_unit_importance(activations, explainn, unit_outputs, unit_index, target_labels)\n",
      "File \u001b[0;32m/pmglocal/ty2514/Enhancer/Enhancer/train/interpretation.py:95\u001b[0m, in \u001b[0;36mget_explainn_unit_outputs\u001b[0;34m(data_loader, model, device)\u001b[0m\n\u001b[1;32m     93\u001b[0m     x \u001b[38;5;241m=\u001b[39m seq\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     94\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;241m1\u001b[39m, model\u001b[38;5;241m.\u001b[39m_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_cnns\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 95\u001b[0m     cnn_output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinears\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     running_cnn_outputs\u001b[38;5;241m.\u001b[39mextend(cnn_output\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     98\u001b[0m running_cnn_outputs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(running_cnn_outputs)\n",
      "File \u001b[0;32m/pmglocal/ty2514/miniforge3/envs/explainn/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/pmglocal/ty2514/miniforge3/envs/explainn/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/pmglocal/ty2514/miniforge3/envs/explainn/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/pmglocal/ty2514/miniforge3/envs/explainn/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/pmglocal/ty2514/miniforge3/envs/explainn/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/pmglocal/ty2514/miniforge3/envs/explainn/lib/python3.10/site-packages/torch/nn/modules/conv.py:310\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/pmglocal/ty2514/miniforge3/envs/explainn/lib/python3.10/site-packages/torch/nn/modules/conv.py:306\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    304\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    305\u001b[0m                     _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Assuming 'interpretation' and 'explainn' are already defined and properly configured\n",
    "# Also assuming 'data_loader', 'device', and 'annotation' are defined as per your setup\n",
    "activations = np.load('/pmglocal/ty2514/Enhancer/Enhancer/data/ExplaiNN_both_results/Model_Activations.npy')\n",
    "\n",
    "unit_importance_GFP_pos = []\n",
    "unit_importance_GFP_neg = []\n",
    "\n",
    "# Loop through units with indices 0 to 4\n",
    "for unit_index in range(num_cnns):\n",
    "    print(unit_index)\n",
    "    # Calculate unit importance for the current unit\n",
    "    unit_outputs = interpretation.get_explainn_unit_outputs(data_loader, explainn, device)\n",
    "    target_labels = ['GFP+','GFP-']\n",
    "    importance = interpretation.get_specific_unit_importance(activations, explainn, unit_outputs, unit_index, target_labels)\n",
    "    unit_importance_GFP_pos.append(importance['GFP+'])\n",
    "    unit_importance_GFP_neg.append(importance['GFP-'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Plot the Ranked Importance Value of Each Filter\"\"\"\n",
    "num_filter_plot = 10\n",
    "# Create a list to store common important filters\n",
    "common_filters = []\n",
    "def plot_importance(unit_importance_values, unit_names, title_suffix):\n",
    "    plt.figure(figsize=(8, math.ceil(0.15 * num_cnns)))\n",
    "\n",
    "    # Calculate the means of each list in unit_importance_values\n",
    "    means = [np.mean(values) for values in unit_importance_values]\n",
    "\n",
    "    # Create tuples of means, unit names, and values, then sort them by means\n",
    "    sorted_data = sorted(zip(means, unit_names, unit_importance_values), key=lambda x: x[0], reverse=True)\n",
    "\n",
    "    # Unzip the sorted data\n",
    "    sorted_means, sorted_names, sorted_values = zip(*sorted_data)\n",
    "\n",
    "    # Print top 10 most impoertant filters\n",
    "    #values_list = [tf_to_filter[name] for name in sorted_names[:10] if name in tf_to_filter]\n",
    "    #common_filters.append(values_list)\n",
    "    #print(values_list)\n",
    "\n",
    "    # Unzip the sorted data\n",
    "    #sorted_means, sorted_names, sorted_values = zip(*sorted_data[:num_filter_plot][::-1])\n",
    "\n",
    "    # Define properties for outliers (fliers)\n",
    "    flierprops = dict(marker='o', color='black', markersize=6)\n",
    "\n",
    "    # Create box plots individually to control colors\n",
    "    box_width = 0.6  # Set box width\n",
    "    for i, (name, data) in enumerate(zip(sorted_names, sorted_values)):\n",
    "        color = \"#ff9999\" if \"filter\" not in name.lower() else \"#228833\"\n",
    "        plt.boxplot(data, positions=[i + 1], widths=box_width, notch=True, patch_artist=True,vert=False,\n",
    "                   boxprops=dict(facecolor=color, color=color), flierprops=flierprops)\n",
    "\n",
    "    # Set custom sorted x-axis labels\n",
    "    plt.set_yticks(range(1, len(sorted_names) + 1))\n",
    "    plt.set_yticklabels(sorted_names, rotation=0)\n",
    "    plt.set_title(f\"Unit Importance of Each Filter on Predicting {title_suffix}\")\n",
    "    plt.set_xlabel(\"Importance Values\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Plot for GFP+ positive\n",
    "plot_importance(unit_importance_GFP_pos, \"GFP Positive\")\n",
    "\n",
    "# Plot for GFP+ negative\n",
    "plot_importance(unit_importance_GFP_neg, \"GFP Negative\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_importance_GFP_pos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "explainn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
