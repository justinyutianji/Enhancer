{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from utils import EnhancerDataset, split_dataset, train_model, regression_model_plot,EnhancerDatasetWithID\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import torch.nn as nn\n",
    "import torch.nn.modules.activation as activation\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "import interpretation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append('../model')  \n",
    "from model import ConvNetDeep, DanQ, ExplaiNN,ConvNetDeep2, ExplaiNN2, ExplaiNN3,DeepSTARR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Model is on device: cuda:0\n",
      "Epoch 1/200, Step 1/60, Loss: 73.9672\n",
      "Epoch 1/200 -- Train Loss: 11.5048 , Validation Loss: 0.3904\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.4032, RMSE=0.6350, MAE=0.5204, R^2=-5.6400, Pearson=0.2230, Spearman=0.2222\n",
      "Label 2: MSE=0.3763, RMSE=0.6134, MAE=0.5003, R^2=-9.9570, Pearson=0.0926, Spearman=0.0899\n",
      "Overall (Flattened): MSE=0.3898, RMSE=0.6243, MAE=0.5103, R^2=-6.7794, Pearson=0.1852, Spearman=0.1729\n",
      "----------------------------------------------------------\n",
      "Epoch 2/200, Step 1/60, Loss: 0.2187\n",
      "Epoch 2/200 -- Train Loss: 0.1489 , Validation Loss: 0.1087\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.1165, RMSE=0.3413, MAE=0.2713, R^2=-0.9189, Pearson=0.2733, Spearman=0.2544\n",
      "Label 2: MSE=0.1011, RMSE=0.3180, MAE=0.2553, R^2=-1.9437, Pearson=0.2098, Spearman=0.1871\n",
      "Overall (Flattened): MSE=0.1088, RMSE=0.3299, MAE=0.2633, R^2=-1.1718, Pearson=0.2726, Spearman=0.2441\n",
      "----------------------------------------------------------\n",
      "Epoch 3/200, Step 1/60, Loss: 0.0999\n",
      "Epoch 3/200 -- Train Loss: 0.0931 , Validation Loss: 0.0680\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0685, RMSE=0.2617, MAE=0.2051, R^2=-0.1282, Pearson=0.4725, Spearman=0.4353\n",
      "Label 2: MSE=0.0672, RMSE=0.2592, MAE=0.2057, R^2=-0.9565, Pearson=0.2555, Spearman=0.2327\n",
      "Overall (Flattened): MSE=0.0678, RMSE=0.2605, MAE=0.2054, R^2=-0.3543, Pearson=0.4155, Spearman=0.3639\n",
      "----------------------------------------------------------\n",
      "Epoch 4/200, Step 1/60, Loss: 0.0741\n",
      "Epoch 4/200 -- Train Loss: 0.0741 , Validation Loss: 0.0560\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0572, RMSE=0.2392, MAE=0.1883, R^2=0.0574, Pearson=0.5191, Spearman=0.4977\n",
      "Label 2: MSE=0.0546, RMSE=0.2337, MAE=0.1854, R^2=-0.5901, Pearson=0.2621, Spearman=0.2484\n",
      "Overall (Flattened): MSE=0.0559, RMSE=0.2365, MAE=0.1868, R^2=-0.1162, Pearson=0.4488, Spearman=0.4021\n",
      "----------------------------------------------------------\n",
      "Epoch 5/200, Step 1/60, Loss: 0.0789\n",
      "Epoch 5/200 -- Train Loss: 0.0657 , Validation Loss: 0.0506\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0519, RMSE=0.2278, MAE=0.1777, R^2=0.1450, Pearson=0.5468, Spearman=0.5279\n",
      "Label 2: MSE=0.0493, RMSE=0.2220, MAE=0.1765, R^2=-0.4348, Pearson=0.2994, Spearman=0.2826\n",
      "Overall (Flattened): MSE=0.0506, RMSE=0.2249, MAE=0.1771, R^2=-0.0099, Pearson=0.4820, Spearman=0.4353\n",
      "----------------------------------------------------------\n",
      "Epoch 6/200, Step 1/60, Loss: 0.0574\n",
      "Epoch 6/200 -- Train Loss: 0.0590 , Validation Loss: 0.0433\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0450, RMSE=0.2122, MAE=0.1676, R^2=0.2585, Pearson=0.5722, Spearman=0.5494\n",
      "Label 2: MSE=0.0416, RMSE=0.2040, MAE=0.1600, R^2=-0.2116, Pearson=0.3437, Spearman=0.3269\n",
      "Overall (Flattened): MSE=0.0433, RMSE=0.2081, MAE=0.1638, R^2=0.1354, Pearson=0.5131, Spearman=0.4661\n",
      "----------------------------------------------------------\n",
      "Epoch 7/200, Step 1/60, Loss: 0.0494\n",
      "Epoch 7/200 -- Train Loss: 0.0535 , Validation Loss: 0.0431\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0450, RMSE=0.2122, MAE=0.1678, R^2=0.2581, Pearson=0.5667, Spearman=0.5448\n",
      "Label 2: MSE=0.0412, RMSE=0.2030, MAE=0.1584, R^2=-0.1994, Pearson=0.3092, Spearman=0.3001\n",
      "Overall (Flattened): MSE=0.0431, RMSE=0.2077, MAE=0.1631, R^2=0.1393, Pearson=0.5027, Spearman=0.4499\n",
      "----------------------------------------------------------\n",
      "Epoch 8/200, Step 1/60, Loss: 0.0522\n",
      "Epoch 8/200 -- Train Loss: 0.0507 , Validation Loss: 0.0405\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0425, RMSE=0.2061, MAE=0.1615, R^2=0.3005, Pearson=0.5765, Spearman=0.5505\n",
      "Label 2: MSE=0.0385, RMSE=0.1963, MAE=0.1553, R^2=-0.1221, Pearson=0.3274, Spearman=0.3104\n",
      "Overall (Flattened): MSE=0.0405, RMSE=0.2013, MAE=0.1584, R^2=0.1915, Pearson=0.5098, Spearman=0.4587\n",
      "----------------------------------------------------------\n",
      "Epoch 9/200, Step 1/60, Loss: 0.0402\n",
      "Epoch 9/200 -- Train Loss: 0.0474 , Validation Loss: 0.0381\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0406, RMSE=0.2015, MAE=0.1574, R^2=0.3314, Pearson=0.5910, Spearman=0.5701\n",
      "Label 2: MSE=0.0355, RMSE=0.1885, MAE=0.1483, R^2=-0.0349, Pearson=0.3643, Spearman=0.3429\n",
      "Overall (Flattened): MSE=0.0381, RMSE=0.1951, MAE=0.1529, R^2=0.2401, Pearson=0.5393, Spearman=0.4874\n",
      "----------------------------------------------------------\n",
      "Epoch 10/200, Step 1/60, Loss: 0.0525\n",
      "Epoch 10/200 -- Train Loss: 0.0462 , Validation Loss: 0.0396\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0419, RMSE=0.2047, MAE=0.1595, R^2=0.3097, Pearson=0.5885, Spearman=0.5563\n",
      "Label 2: MSE=0.0373, RMSE=0.1931, MAE=0.1525, R^2=-0.0861, Pearson=0.3482, Spearman=0.3216\n",
      "Overall (Flattened): MSE=0.0396, RMSE=0.1990, MAE=0.1560, R^2=0.2094, Pearson=0.5274, Spearman=0.4664\n",
      "----------------------------------------------------------\n",
      "Epoch 11/200, Step 1/60, Loss: 0.0445\n",
      "Epoch 11/200 -- Train Loss: 0.0441 , Validation Loss: 0.0382\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0403, RMSE=0.2008, MAE=0.1573, R^2=0.3357, Pearson=0.6188, Spearman=0.5945\n",
      "Label 2: MSE=0.0362, RMSE=0.1903, MAE=0.1496, R^2=-0.0543, Pearson=0.3606, Spearman=0.3386\n",
      "Overall (Flattened): MSE=0.0383, RMSE=0.1956, MAE=0.1535, R^2=0.2361, Pearson=0.5561, Spearman=0.4949\n",
      "----------------------------------------------------------\n",
      "Epoch 12/200, Step 1/60, Loss: 0.0417\n",
      "Epoch 12/200 -- Train Loss: 0.0424 , Validation Loss: 0.0384\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0398, RMSE=0.1996, MAE=0.1556, R^2=0.3440, Pearson=0.6051, Spearman=0.5668\n",
      "Label 2: MSE=0.0369, RMSE=0.1920, MAE=0.1507, R^2=-0.0738, Pearson=0.3290, Spearman=0.3033\n",
      "Overall (Flattened): MSE=0.0384, RMSE=0.1958, MAE=0.1532, R^2=0.2344, Pearson=0.5394, Spearman=0.4667\n",
      "----------------------------------------------------------\n",
      "Epoch 13/200, Step 1/60, Loss: 0.0381\n",
      "Epoch 13/200 -- Train Loss: 0.0404 , Validation Loss: 0.0395\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0412, RMSE=0.2031, MAE=0.1594, R^2=0.3210, Pearson=0.6008, Spearman=0.5805\n",
      "Label 2: MSE=0.0377, RMSE=0.1943, MAE=0.1535, R^2=-0.0989, Pearson=0.3399, Spearman=0.3187\n",
      "Overall (Flattened): MSE=0.0395, RMSE=0.1987, MAE=0.1565, R^2=0.2119, Pearson=0.5399, Spearman=0.4802\n",
      "----------------------------------------------------------\n",
      "Epoch 14/200, Step 1/60, Loss: 0.0379\n",
      "Epoch 14/200 -- Train Loss: 0.0390 , Validation Loss: 0.0370\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0392, RMSE=0.1980, MAE=0.1542, R^2=0.3544, Pearson=0.6156, Spearman=0.5847\n",
      "Label 2: MSE=0.0345, RMSE=0.1859, MAE=0.1467, R^2=-0.0059, Pearson=0.3510, Spearman=0.3348\n",
      "Overall (Flattened): MSE=0.0369, RMSE=0.1920, MAE=0.1505, R^2=0.2640, Pearson=0.5593, Spearman=0.4903\n",
      "----------------------------------------------------------\n",
      "Epoch 15/200, Step 1/60, Loss: 0.0340\n",
      "Epoch 15/200 -- Train Loss: 0.0391 , Validation Loss: 0.0358\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0374, RMSE=0.1933, MAE=0.1521, R^2=0.3844, Pearson=0.6331, Spearman=0.5958\n",
      "Label 2: MSE=0.0341, RMSE=0.1847, MAE=0.1455, R^2=0.0072, Pearson=0.3731, Spearman=0.3454\n",
      "Overall (Flattened): MSE=0.0357, RMSE=0.1890, MAE=0.1488, R^2=0.2867, Pearson=0.5694, Spearman=0.4988\n",
      "----------------------------------------------------------\n",
      "Epoch 16/200, Step 1/60, Loss: 0.0391\n",
      "Epoch 16/200 -- Train Loss: 0.0368 , Validation Loss: 0.0357\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0376, RMSE=0.1939, MAE=0.1503, R^2=0.3805, Pearson=0.6400, Spearman=0.6098\n",
      "Label 2: MSE=0.0337, RMSE=0.1836, MAE=0.1445, R^2=0.0190, Pearson=0.3657, Spearman=0.3374\n",
      "Overall (Flattened): MSE=0.0357, RMSE=0.1888, MAE=0.1474, R^2=0.2883, Pearson=0.5729, Spearman=0.5020\n",
      "----------------------------------------------------------\n",
      "Epoch 17/200, Step 1/60, Loss: 0.0280\n",
      "Epoch 17/200 -- Train Loss: 0.0364 , Validation Loss: 0.0356\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0374, RMSE=0.1933, MAE=0.1497, R^2=0.3846, Pearson=0.6324, Spearman=0.6020\n",
      "Label 2: MSE=0.0338, RMSE=0.1837, MAE=0.1443, R^2=0.0171, Pearson=0.3528, Spearman=0.3320\n",
      "Overall (Flattened): MSE=0.0356, RMSE=0.1886, MAE=0.1470, R^2=0.2902, Pearson=0.5670, Spearman=0.4981\n",
      "----------------------------------------------------------\n",
      "Epoch 18/200, Step 1/60, Loss: 0.0356\n",
      "Epoch 18/200 -- Train Loss: 0.0354 , Validation Loss: 0.0359\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0389, RMSE=0.1973, MAE=0.1533, R^2=0.3589, Pearson=0.6233, Spearman=0.5930\n",
      "Label 2: MSE=0.0327, RMSE=0.1809, MAE=0.1437, R^2=0.0471, Pearson=0.3853, Spearman=0.3585\n",
      "Overall (Flattened): MSE=0.0358, RMSE=0.1893, MAE=0.1485, R^2=0.2849, Pearson=0.5666, Spearman=0.5014\n",
      "----------------------------------------------------------\n",
      "Epoch 19/200, Step 1/60, Loss: 0.0255\n",
      "Epoch 19/200 -- Train Loss: 0.0345 , Validation Loss: 0.0362\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0385, RMSE=0.1962, MAE=0.1540, R^2=0.3661, Pearson=0.6329, Spearman=0.6005\n",
      "Label 2: MSE=0.0340, RMSE=0.1843, MAE=0.1452, R^2=0.0114, Pearson=0.3663, Spearman=0.3477\n",
      "Overall (Flattened): MSE=0.0362, RMSE=0.1903, MAE=0.1496, R^2=0.2770, Pearson=0.5727, Spearman=0.5037\n",
      "----------------------------------------------------------\n",
      "Epoch 20/200, Step 1/60, Loss: 0.0318\n",
      "Epoch 20/200 -- Train Loss: 0.0324 , Validation Loss: 0.0363\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0381, RMSE=0.1952, MAE=0.1527, R^2=0.3722, Pearson=0.6359, Spearman=0.5935\n",
      "Label 2: MSE=0.0346, RMSE=0.1859, MAE=0.1461, R^2=-0.0062, Pearson=0.3734, Spearman=0.3450\n",
      "Overall (Flattened): MSE=0.0363, RMSE=0.1906, MAE=0.1494, R^2=0.2747, Pearson=0.5727, Spearman=0.4964\n",
      "----------------------------------------------------------\n",
      "Epoch 21/200, Step 1/60, Loss: 0.0273\n",
      "Epoch 21/200 -- Train Loss: 0.0334 , Validation Loss: 0.0365\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0394, RMSE=0.1985, MAE=0.1542, R^2=0.3514, Pearson=0.6053, Spearman=0.5697\n",
      "Label 2: MSE=0.0337, RMSE=0.1835, MAE=0.1443, R^2=0.0199, Pearson=0.3931, Spearman=0.3687\n",
      "Overall (Flattened): MSE=0.0365, RMSE=0.1911, MAE=0.1493, R^2=0.2710, Pearson=0.5569, Spearman=0.4960\n",
      "----------------------------------------------------------\n",
      "Epoch 22/200, Step 1/60, Loss: 0.0380\n",
      "Epoch 22/200 -- Train Loss: 0.0330 , Validation Loss: 0.0355\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0373, RMSE=0.1931, MAE=0.1505, R^2=0.3856, Pearson=0.6343, Spearman=0.6004\n",
      "Label 2: MSE=0.0338, RMSE=0.1839, MAE=0.1443, R^2=0.0154, Pearson=0.3601, Spearman=0.3336\n",
      "Overall (Flattened): MSE=0.0356, RMSE=0.1886, MAE=0.1474, R^2=0.2902, Pearson=0.5708, Spearman=0.4994\n",
      "----------------------------------------------------------\n",
      "Epoch 23/200, Step 1/60, Loss: 0.0266\n",
      "Epoch 23/200 -- Train Loss: 0.0328 , Validation Loss: 0.0357\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0373, RMSE=0.1932, MAE=0.1507, R^2=0.3851, Pearson=0.6402, Spearman=0.6012\n",
      "Label 2: MSE=0.0341, RMSE=0.1847, MAE=0.1456, R^2=0.0072, Pearson=0.3510, Spearman=0.3233\n",
      "Overall (Flattened): MSE=0.0357, RMSE=0.1890, MAE=0.1481, R^2=0.2871, Pearson=0.5727, Spearman=0.4919\n",
      "----------------------------------------------------------\n",
      "Epoch 24/200, Step 1/60, Loss: 0.0287\n",
      "Epoch 24/200 -- Train Loss: 0.0318 , Validation Loss: 0.0351\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0368, RMSE=0.1919, MAE=0.1484, R^2=0.3937, Pearson=0.6398, Spearman=0.6019\n",
      "Label 2: MSE=0.0334, RMSE=0.1827, MAE=0.1432, R^2=0.0283, Pearson=0.3796, Spearman=0.3561\n",
      "Overall (Flattened): MSE=0.0351, RMSE=0.1873, MAE=0.1458, R^2=0.2995, Pearson=0.5822, Spearman=0.5071\n",
      "----------------------------------------------------------\n",
      "Epoch 25/200, Step 1/60, Loss: 0.0264\n",
      "Epoch 25/200 -- Train Loss: 0.0308 , Validation Loss: 0.0366\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0389, RMSE=0.1972, MAE=0.1530, R^2=0.3596, Pearson=0.6225, Spearman=0.5900\n",
      "Label 2: MSE=0.0344, RMSE=0.1855, MAE=0.1461, R^2=-0.0015, Pearson=0.3753, Spearman=0.3592\n",
      "Overall (Flattened): MSE=0.0366, RMSE=0.1914, MAE=0.1496, R^2=0.2686, Pearson=0.5704, Spearman=0.5038\n",
      "----------------------------------------------------------\n",
      "Epoch 26/200, Step 1/60, Loss: 0.0347\n",
      "Epoch 26/200 -- Train Loss: 0.0312 , Validation Loss: 0.0363\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0382, RMSE=0.1955, MAE=0.1508, R^2=0.3707, Pearson=0.6290, Spearman=0.5871\n",
      "Label 2: MSE=0.0344, RMSE=0.1855, MAE=0.1451, R^2=-0.0021, Pearson=0.3794, Spearman=0.3628\n",
      "Overall (Flattened): MSE=0.0363, RMSE=0.1906, MAE=0.1480, R^2=0.2752, Pearson=0.5676, Spearman=0.4969\n",
      "----------------------------------------------------------\n",
      "Epoch 27/200, Step 1/60, Loss: 0.0290\n",
      "Epoch 27/200 -- Train Loss: 0.0307 , Validation Loss: 0.0376\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0410, RMSE=0.2025, MAE=0.1591, R^2=0.3244, Pearson=0.6165, Spearman=0.5725\n",
      "Label 2: MSE=0.0342, RMSE=0.1851, MAE=0.1460, R^2=0.0029, Pearson=0.3932, Spearman=0.3701\n",
      "Overall (Flattened): MSE=0.0376, RMSE=0.1940, MAE=0.1526, R^2=0.2488, Pearson=0.5640, Spearman=0.4949\n",
      "----------------------------------------------------------\n",
      "Epoch 28/200, Step 1/60, Loss: 0.0318\n",
      "Epoch 28/200 -- Train Loss: 0.0298 , Validation Loss: 0.0354\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0377, RMSE=0.1943, MAE=0.1503, R^2=0.3786, Pearson=0.6390, Spearman=0.6022\n",
      "Label 2: MSE=0.0330, RMSE=0.1817, MAE=0.1422, R^2=0.0382, Pearson=0.3964, Spearman=0.3750\n",
      "Overall (Flattened): MSE=0.0354, RMSE=0.1881, MAE=0.1462, R^2=0.2938, Pearson=0.5805, Spearman=0.5104\n",
      "----------------------------------------------------------\n",
      "Epoch 29/200, Step 1/60, Loss: 0.0309\n",
      "Epoch 29/200 -- Train Loss: 0.0293 , Validation Loss: 0.0356\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0378, RMSE=0.1944, MAE=0.1497, R^2=0.3777, Pearson=0.6269, Spearman=0.5910\n",
      "Label 2: MSE=0.0334, RMSE=0.1828, MAE=0.1428, R^2=0.0270, Pearson=0.3717, Spearman=0.3487\n",
      "Overall (Flattened): MSE=0.0356, RMSE=0.1887, MAE=0.1462, R^2=0.2894, Pearson=0.5699, Spearman=0.4998\n",
      "----------------------------------------------------------\n",
      "Epoch 30/200, Step 1/60, Loss: 0.0274\n",
      "Epoch 30/200 -- Train Loss: 0.0285 , Validation Loss: 0.0349\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0366, RMSE=0.1913, MAE=0.1480, R^2=0.3972, Pearson=0.6514, Spearman=0.6127\n",
      "Label 2: MSE=0.0332, RMSE=0.1822, MAE=0.1435, R^2=0.0339, Pearson=0.3969, Spearman=0.3660\n",
      "Overall (Flattened): MSE=0.0349, RMSE=0.1868, MAE=0.1457, R^2=0.3035, Pearson=0.5871, Spearman=0.5126\n",
      "----------------------------------------------------------\n",
      "Epoch 31/200, Step 1/60, Loss: 0.0266\n",
      "Epoch 31/200 -- Train Loss: 0.0281 , Validation Loss: 0.0363\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0388, RMSE=0.1970, MAE=0.1538, R^2=0.3608, Pearson=0.6252, Spearman=0.5810\n",
      "Label 2: MSE=0.0338, RMSE=0.1837, MAE=0.1450, R^2=0.0171, Pearson=0.3724, Spearman=0.3407\n",
      "Overall (Flattened): MSE=0.0363, RMSE=0.1905, MAE=0.1494, R^2=0.2758, Pearson=0.5663, Spearman=0.4884\n",
      "----------------------------------------------------------\n",
      "Epoch 32/200, Step 1/60, Loss: 0.0281\n",
      "Epoch 32/200 -- Train Loss: 0.0286 , Validation Loss: 0.0347\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0372, RMSE=0.1930, MAE=0.1505, R^2=0.3867, Pearson=0.6416, Spearman=0.6011\n",
      "Label 2: MSE=0.0323, RMSE=0.1798, MAE=0.1407, R^2=0.0587, Pearson=0.3851, Spearman=0.3581\n",
      "Overall (Flattened): MSE=0.0348, RMSE=0.1865, MAE=0.1456, R^2=0.3057, Pearson=0.5853, Spearman=0.5071\n",
      "----------------------------------------------------------\n",
      "Epoch 33/200, Step 1/60, Loss: 0.0236\n",
      "Epoch 33/200 -- Train Loss: 0.0274 , Validation Loss: 0.0349\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0376, RMSE=0.1939, MAE=0.1508, R^2=0.3809, Pearson=0.6318, Spearman=0.5879\n",
      "Label 2: MSE=0.0322, RMSE=0.1794, MAE=0.1407, R^2=0.0629, Pearson=0.3968, Spearman=0.3712\n",
      "Overall (Flattened): MSE=0.0349, RMSE=0.1868, MAE=0.1458, R^2=0.3037, Pearson=0.5810, Spearman=0.5045\n",
      "----------------------------------------------------------\n",
      "Epoch 34/200, Step 1/60, Loss: 0.0229\n",
      "Epoch 34/200 -- Train Loss: 0.0271 , Validation Loss: 0.0350\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0368, RMSE=0.1919, MAE=0.1482, R^2=0.3938, Pearson=0.6447, Spearman=0.6086\n",
      "Label 2: MSE=0.0332, RMSE=0.1821, MAE=0.1423, R^2=0.0343, Pearson=0.3624, Spearman=0.3361\n",
      "Overall (Flattened): MSE=0.0350, RMSE=0.1870, MAE=0.1452, R^2=0.3017, Pearson=0.5802, Spearman=0.5027\n",
      "----------------------------------------------------------\n",
      "Epoch 35/200, Step 1/60, Loss: 0.0256\n",
      "Epoch 35/200 -- Train Loss: 0.0271 , Validation Loss: 0.0375\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0391, RMSE=0.1977, MAE=0.1542, R^2=0.3562, Pearson=0.6193, Spearman=0.5792\n",
      "Label 2: MSE=0.0359, RMSE=0.1896, MAE=0.1492, R^2=-0.0467, Pearson=0.3599, Spearman=0.3386\n",
      "Overall (Flattened): MSE=0.0375, RMSE=0.1937, MAE=0.1517, R^2=0.2511, Pearson=0.5601, Spearman=0.4887\n",
      "----------------------------------------------------------\n",
      "Epoch 36/200, Step 1/60, Loss: 0.0256\n",
      "Epoch 36/200 -- Train Loss: 0.0260 , Validation Loss: 0.0357\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0383, RMSE=0.1957, MAE=0.1523, R^2=0.3694, Pearson=0.6352, Spearman=0.5894\n",
      "Label 2: MSE=0.0332, RMSE=0.1822, MAE=0.1431, R^2=0.0329, Pearson=0.3808, Spearman=0.3543\n",
      "Overall (Flattened): MSE=0.0358, RMSE=0.1891, MAE=0.1477, R^2=0.2864, Pearson=0.5790, Spearman=0.4977\n",
      "----------------------------------------------------------\n",
      "Epoch 37/200, Step 1/60, Loss: 0.0229\n",
      "Epoch 37/200 -- Train Loss: 0.0264 , Validation Loss: 0.0357\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0386, RMSE=0.1965, MAE=0.1521, R^2=0.3643, Pearson=0.6367, Spearman=0.6000\n",
      "Label 2: MSE=0.0329, RMSE=0.1815, MAE=0.1435, R^2=0.0409, Pearson=0.4012, Spearman=0.3726\n",
      "Overall (Flattened): MSE=0.0358, RMSE=0.1891, MAE=0.1478, R^2=0.2860, Pearson=0.5767, Spearman=0.5068\n",
      "----------------------------------------------------------\n",
      "Epoch 38/200, Step 1/60, Loss: 0.0218\n",
      "Epoch 38/200 -- Train Loss: 0.0256 , Validation Loss: 0.0357\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0376, RMSE=0.1940, MAE=0.1505, R^2=0.3801, Pearson=0.6389, Spearman=0.6004\n",
      "Label 2: MSE=0.0338, RMSE=0.1837, MAE=0.1456, R^2=0.0172, Pearson=0.3766, Spearman=0.3427\n",
      "Overall (Flattened): MSE=0.0357, RMSE=0.1889, MAE=0.1480, R^2=0.2875, Pearson=0.5780, Spearman=0.5017\n",
      "----------------------------------------------------------\n",
      "Epoch 39/200, Step 1/60, Loss: 0.0218\n",
      "Epoch 39/200 -- Train Loss: 0.0262 , Validation Loss: 0.0360\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0379, RMSE=0.1947, MAE=0.1505, R^2=0.3755, Pearson=0.6403, Spearman=0.5938\n",
      "Label 2: MSE=0.0342, RMSE=0.1850, MAE=0.1445, R^2=0.0038, Pearson=0.3946, Spearman=0.3641\n",
      "Overall (Flattened): MSE=0.0361, RMSE=0.1899, MAE=0.1475, R^2=0.2801, Pearson=0.5856, Spearman=0.5051\n",
      "----------------------------------------------------------\n",
      "Epoch 40/200, Step 1/60, Loss: 0.0274\n",
      "Epoch 40/200 -- Train Loss: 0.0264 , Validation Loss: 0.0359\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0381, RMSE=0.1951, MAE=0.1529, R^2=0.3730, Pearson=0.6342, Spearman=0.5892\n",
      "Label 2: MSE=0.0338, RMSE=0.1838, MAE=0.1442, R^2=0.0167, Pearson=0.3577, Spearman=0.3290\n",
      "Overall (Flattened): MSE=0.0359, RMSE=0.1895, MAE=0.1486, R^2=0.2830, Pearson=0.5665, Spearman=0.4858\n",
      "----------------------------------------------------------\n",
      "Epoch 41/200, Step 1/60, Loss: 0.0246\n",
      "Epoch 41/200 -- Train Loss: 0.0254 , Validation Loss: 0.0355\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0372, RMSE=0.1929, MAE=0.1498, R^2=0.3870, Pearson=0.6452, Spearman=0.6103\n",
      "Label 2: MSE=0.0339, RMSE=0.1841, MAE=0.1452, R^2=0.0133, Pearson=0.3872, Spearman=0.3623\n",
      "Overall (Flattened): MSE=0.0356, RMSE=0.1886, MAE=0.1475, R^2=0.2903, Pearson=0.5900, Spearman=0.5163\n",
      "----------------------------------------------------------\n",
      "Epoch 42/200, Step 1/60, Loss: 0.0283\n",
      "Epoch 42/200 -- Train Loss: 0.0263 , Validation Loss: 0.0354\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0378, RMSE=0.1944, MAE=0.1509, R^2=0.3779, Pearson=0.6397, Spearman=0.6027\n",
      "Label 2: MSE=0.0330, RMSE=0.1817, MAE=0.1420, R^2=0.0388, Pearson=0.3913, Spearman=0.3715\n",
      "Overall (Flattened): MSE=0.0354, RMSE=0.1881, MAE=0.1464, R^2=0.2936, Pearson=0.5817, Spearman=0.5111\n",
      "----------------------------------------------------------\n",
      "Epoch 43/200, Step 1/60, Loss: 0.0305\n",
      "Epoch 43/200 -- Train Loss: 0.0251 , Validation Loss: 0.0449\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0482, RMSE=0.2195, MAE=0.1718, R^2=0.2064, Pearson=0.6356, Spearman=0.5978\n",
      "Label 2: MSE=0.0417, RMSE=0.2041, MAE=0.1628, R^2=-0.2129, Pearson=0.3753, Spearman=0.3471\n",
      "Overall (Flattened): MSE=0.0449, RMSE=0.2120, MAE=0.1673, R^2=0.1033, Pearson=0.5742, Spearman=0.4984\n",
      "----------------------------------------------------------\n",
      "Epoch 44/200, Step 1/60, Loss: 0.0300\n",
      "Epoch 44/200 -- Train Loss: 0.0265 , Validation Loss: 0.0403\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0428, RMSE=0.2068, MAE=0.1628, R^2=0.2958, Pearson=0.6344, Spearman=0.5826\n",
      "Label 2: MSE=0.0380, RMSE=0.1950, MAE=0.1541, R^2=-0.1077, Pearson=0.3870, Spearman=0.3639\n",
      "Overall (Flattened): MSE=0.0404, RMSE=0.2010, MAE=0.1584, R^2=0.1936, Pearson=0.5780, Spearman=0.4982\n",
      "----------------------------------------------------------\n",
      "Epoch 45/200, Step 1/60, Loss: 0.0349\n",
      "Epoch 45/200 -- Train Loss: 0.0247 , Validation Loss: 0.0366\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0386, RMSE=0.1964, MAE=0.1515, R^2=0.3648, Pearson=0.6340, Spearman=0.5905\n",
      "Label 2: MSE=0.0346, RMSE=0.1861, MAE=0.1472, R^2=-0.0087, Pearson=0.3857, Spearman=0.3541\n",
      "Overall (Flattened): MSE=0.0366, RMSE=0.1913, MAE=0.1493, R^2=0.2694, Pearson=0.5763, Spearman=0.4981\n",
      "----------------------------------------------------------\n",
      "Epoch 46/200, Step 1/60, Loss: 0.0238\n",
      "Epoch 46/200 -- Train Loss: 0.0244 , Validation Loss: 0.0355\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0372, RMSE=0.1930, MAE=0.1503, R^2=0.3866, Pearson=0.6401, Spearman=0.5938\n",
      "Label 2: MSE=0.0337, RMSE=0.1837, MAE=0.1448, R^2=0.0175, Pearson=0.3951, Spearman=0.3638\n",
      "Overall (Flattened): MSE=0.0355, RMSE=0.1884, MAE=0.1475, R^2=0.2915, Pearson=0.5857, Spearman=0.5065\n",
      "----------------------------------------------------------\n",
      "Epoch 47/200, Step 1/60, Loss: 0.0222\n",
      "Epoch 47/200 -- Train Loss: 0.0253 , Validation Loss: 0.0383\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0432, RMSE=0.2079, MAE=0.1646, R^2=0.2881, Pearson=0.6389, Spearman=0.6019\n",
      "Label 2: MSE=0.0336, RMSE=0.1834, MAE=0.1443, R^2=0.0209, Pearson=0.3715, Spearman=0.3468\n",
      "Overall (Flattened): MSE=0.0384, RMSE=0.1960, MAE=0.1545, R^2=0.2330, Pearson=0.5800, Spearman=0.5025\n",
      "----------------------------------------------------------\n",
      "Early stopping triggered at epoch 47\n",
      "Finished Training!\n",
      "Best Pearson Correlation is 0.5899631713484053 at epoch 40\n",
      "Best R2 Square Correlation is 0.3056932128223687 at epoch 31\n",
      "\n",
      "\n",
      "*** Deleting model paths ***\n",
      "Evaluating model at best_r2 epoch: 31\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0400, RMSE=0.1999, MAE=0.1535, R^2=0.3280, Pearson=0.6068, Spearman=0.5752\n",
      "Label 2: MSE=0.0345, RMSE=0.1858, MAE=0.1440, R^2=0.0713, Pearson=0.3919, Spearman=0.3779\n",
      "Overall (Flattened): MSE=0.0373, RMSE=0.1930, MAE=0.1488, R^2=0.2655, Pearson=0.5593, Spearman=0.4997\n",
      "----------------------------------------------------------\n",
      "Model at best_r2 epoch 31 is saved as best_r2_model\n",
      "Evaluating model at best_pearson epoch: 40\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0403, RMSE=0.2008, MAE=0.1530, R^2=0.3220, Pearson=0.6030, Spearman=0.5708\n",
      "Label 2: MSE=0.0340, RMSE=0.1845, MAE=0.1440, R^2=0.0845, Pearson=0.4131, Spearman=0.3887\n",
      "Overall (Flattened): MSE=0.0372, RMSE=0.1928, MAE=0.1485, R^2=0.2668, Pearson=0.5661, Spearman=0.5041\n",
      "----------------------------------------------------------\n",
      "Model at best_pearson epoch 40 is saved as best_pearson_model\n",
      "All contents in /pmglocal/ty2514/Enhancer/Enhancer/data/ExplaiNN_GFP_70NN have been deleted as save_model is set to False.\n"
     ]
    }
   ],
   "source": [
    "# Directory to save the result\n",
    "seed = 42\n",
    "batch = 168\n",
    "num_cnns = 70\n",
    "learning_rate= 1e-2\n",
    "target_labels = [\"GFP+\",\"GFP-\"]\n",
    "output_dir = '/pmglocal/ty2514/Enhancer/Enhancer/data/ExplaiNN_GFP_70NN'\n",
    "\n",
    "df = pd.read_csv('/pmglocal/ty2514/Enhancer/Enhancer/data/filtered_input_data.csv')\n",
    "\n",
    "#train, test = split_dataset(df, split_type='fragment', key= 0, seed = 42)\n",
    "train_df, val_df, test_df = split_dataset(df, split_type='random', split_pattern=[0.7, 0.15, 0.15], seed=seed)\n",
    "\n",
    "# Process datasets\n",
    "train = EnhancerDatasetWithID(train_df, feature_list=['G+','G-'], scale_mode = 'none')\n",
    "test = EnhancerDatasetWithID(test_df, feature_list=['G+','G-'], scale_mode = 'none')\n",
    "validation = EnhancerDatasetWithID(val_df, feature_list=['G+','G-'], scale_mode = 'none')\n",
    "\n",
    "# DataLoader setup\n",
    "train_loader = DataLoader(dataset=train, batch_size=batch, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test, batch_size=batch, shuffle=False)\n",
    "val_loader = DataLoader(dataset=validation, batch_size=168, shuffle=False)\n",
    "\n",
    "\n",
    "input_model = ExplaiNN3(num_cnns = num_cnns, input_length = 608, num_classes = 2, \n",
    "                 filter_size = 19, num_fc=2, pool_size=7, pool_stride=7, \n",
    "                 drop_out = 0.3, weight_path = None)# Training\n",
    "\n",
    "_, _, model, train_losses_by_batch, test_losses_by_batch, results, best_pearson_epoch, best_r2_epoch, peasron_metric, r2_metric, device  = train_model(input_model, train_loader, val_loader,test_loader, target_labels=target_labels,\n",
    "                                                                                                                            num_epochs=200, \n",
    "                                                                                         batch_size=batch, learning_rate=learning_rate, \n",
    "                                                                                         criteria='mse',optimizer_type = \"adam\", patience=15, \n",
    "                                                                                         seed = seed, save_model= False, dir_path=output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropout0.3_ba96_lr0.00500_seed9\n",
      "Using device: cuda\n",
      "Model is on device: cuda:0\n",
      "Epoch 1/200, Step 1/105, Loss: 77.4678\n",
      "Epoch 1/200 -- Train Loss: 2.8041 , Validation Loss: 0.2304\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.2537, RMSE=0.5037, MAE=0.3887, R^2=-3.3235, Pearson=0.1795, Spearman=0.1797\n",
      "Label 2: MSE=0.2083, RMSE=0.4564, MAE=0.3534, R^2=-4.8316, Pearson=0.1390, Spearman=0.1427\n",
      "Overall (Flattened): MSE=0.2310, RMSE=0.4806, MAE=0.3710, R^2=-3.7020, Pearson=0.1828, Spearman=0.1814\n",
      "----------------------------------------------------------\n",
      "Epoch 2/200, Step 1/105, Loss: 0.3827\n",
      "Epoch 2/200 -- Train Loss: 0.2950 , Validation Loss: 0.1602\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.1789, RMSE=0.4230, MAE=0.3357, R^2=-2.0489, Pearson=0.2065, Spearman=0.2109\n",
      "Label 2: MSE=0.1405, RMSE=0.3748, MAE=0.2970, R^2=-2.9319, Pearson=0.1302, Spearman=0.1289\n",
      "Overall (Flattened): MSE=0.1597, RMSE=0.3996, MAE=0.3163, R^2=-2.2502, Pearson=0.1791, Spearman=0.1742\n",
      "----------------------------------------------------------\n",
      "Epoch 3/200, Step 1/105, Loss: 0.3603\n",
      "Epoch 3/200 -- Train Loss: 0.2669 , Validation Loss: 0.1133\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.1248, RMSE=0.3532, MAE=0.2828, R^2=-1.1264, Pearson=0.3022, Spearman=0.3047\n",
      "Label 2: MSE=0.1022, RMSE=0.3197, MAE=0.2581, R^2=-1.8613, Pearson=0.1609, Spearman=0.1666\n",
      "Overall (Flattened): MSE=0.1135, RMSE=0.3369, MAE=0.2705, R^2=-1.3101, Pearson=0.2567, Spearman=0.2514\n",
      "----------------------------------------------------------\n",
      "Epoch 4/200, Step 1/105, Loss: 0.1931\n",
      "Epoch 4/200 -- Train Loss: 0.2644 , Validation Loss: 0.0693\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0793, RMSE=0.2816, MAE=0.2212, R^2=-0.3518, Pearson=0.3752, Spearman=0.3715\n",
      "Label 2: MSE=0.0599, RMSE=0.2448, MAE=0.1911, R^2=-0.6782, Pearson=0.1656, Spearman=0.1660\n",
      "Overall (Flattened): MSE=0.0696, RMSE=0.2639, MAE=0.2062, R^2=-0.4173, Pearson=0.3099, Spearman=0.2914\n",
      "----------------------------------------------------------\n",
      "Epoch 5/200, Step 1/105, Loss: 0.2087\n",
      "Epoch 5/200 -- Train Loss: 0.2235 , Validation Loss: 0.1297\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.1304, RMSE=0.3610, MAE=0.2815, R^2=-1.2216, Pearson=0.2232, Spearman=0.2104\n",
      "Label 2: MSE=0.1279, RMSE=0.3576, MAE=0.2782, R^2=-2.5794, Pearson=0.1677, Spearman=0.1540\n",
      "Overall (Flattened): MSE=0.1291, RMSE=0.3593, MAE=0.2798, R^2=-1.6280, Pearson=0.2281, Spearman=0.2079\n",
      "----------------------------------------------------------\n",
      "Epoch 6/200, Step 1/105, Loss: 0.2270\n",
      "Epoch 6/200 -- Train Loss: 0.2204 , Validation Loss: 0.1665\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.1596, RMSE=0.3995, MAE=0.3262, R^2=-1.7201, Pearson=0.2962, Spearman=0.2987\n",
      "Label 2: MSE=0.1702, RMSE=0.4126, MAE=0.3378, R^2=-3.7646, Pearson=0.1489, Spearman=0.1483\n",
      "Overall (Flattened): MSE=0.1649, RMSE=0.4061, MAE=0.3320, R^2=-2.3566, Pearson=0.2620, Spearman=0.2577\n",
      "----------------------------------------------------------\n",
      "Epoch 7/200, Step 1/105, Loss: 0.2484\n",
      "Epoch 7/200 -- Train Loss: 0.2120 , Validation Loss: 0.0750\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0819, RMSE=0.2861, MAE=0.2257, R^2=-0.3952, Pearson=0.3378, Spearman=0.3134\n",
      "Label 2: MSE=0.0685, RMSE=0.2618, MAE=0.2092, R^2=-0.9180, Pearson=0.1770, Spearman=0.1629\n",
      "Overall (Flattened): MSE=0.0752, RMSE=0.2742, MAE=0.2174, R^2=-0.5305, Pearson=0.2857, Spearman=0.2560\n",
      "----------------------------------------------------------\n",
      "Epoch 8/200, Step 1/105, Loss: 0.1627\n",
      "Epoch 8/200 -- Train Loss: 0.1961 , Validation Loss: 0.3185\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.3151, RMSE=0.5613, MAE=0.4669, R^2=-4.3700, Pearson=0.1951, Spearman=0.2112\n",
      "Label 2: MSE=0.3196, RMSE=0.5653, MAE=0.4702, R^2=-7.9468, Pearson=0.0731, Spearman=0.0821\n",
      "Overall (Flattened): MSE=0.3173, RMSE=0.5633, MAE=0.4686, R^2=-5.4595, Pearson=0.1604, Spearman=0.1674\n",
      "----------------------------------------------------------\n",
      "Epoch 9/200, Step 1/105, Loss: 0.4813\n",
      "Epoch 9/200 -- Train Loss: 0.2071 , Validation Loss: 0.0537\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0596, RMSE=0.2441, MAE=0.1918, R^2=-0.0155, Pearson=0.4059, Spearman=0.3851\n",
      "Label 2: MSE=0.0481, RMSE=0.2192, MAE=0.1718, R^2=-0.3455, Pearson=0.2512, Spearman=0.2507\n",
      "Overall (Flattened): MSE=0.0538, RMSE=0.2320, MAE=0.1818, R^2=-0.0956, Pearson=0.3563, Spearman=0.3311\n",
      "----------------------------------------------------------\n",
      "Epoch 10/200, Step 1/105, Loss: 0.1796\n",
      "Epoch 10/200 -- Train Loss: 0.1657 , Validation Loss: 0.0818\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0770, RMSE=0.2775, MAE=0.2157, R^2=-0.3125, Pearson=0.3544, Spearman=0.3470\n",
      "Label 2: MSE=0.0868, RMSE=0.2946, MAE=0.2327, R^2=-1.4290, Pearson=0.0916, Spearman=0.0960\n",
      "Overall (Flattened): MSE=0.0819, RMSE=0.2862, MAE=0.2242, R^2=-0.6669, Pearson=0.2460, Spearman=0.2225\n",
      "----------------------------------------------------------\n",
      "Epoch 11/200, Step 1/105, Loss: 0.2200\n",
      "Epoch 11/200 -- Train Loss: 0.1732 , Validation Loss: 0.0583\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0621, RMSE=0.2492, MAE=0.1988, R^2=-0.0585, Pearson=0.4601, Spearman=0.4318\n",
      "Label 2: MSE=0.0544, RMSE=0.2333, MAE=0.1814, R^2=-0.5231, Pearson=0.1542, Spearman=0.1372\n",
      "Overall (Flattened): MSE=0.0583, RMSE=0.2414, MAE=0.1901, R^2=-0.1859, Pearson=0.3844, Spearman=0.3193\n",
      "----------------------------------------------------------\n",
      "Epoch 12/200, Step 1/105, Loss: 0.1537\n",
      "Epoch 12/200 -- Train Loss: 0.1757 , Validation Loss: 0.0779\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0747, RMSE=0.2734, MAE=0.2187, R^2=-0.2735, Pearson=0.3649, Spearman=0.3533\n",
      "Label 2: MSE=0.0802, RMSE=0.2832, MAE=0.2193, R^2=-1.2455, Pearson=0.1970, Spearman=0.2053\n",
      "Overall (Flattened): MSE=0.0775, RMSE=0.2783, MAE=0.2190, R^2=-0.5769, Pearson=0.2884, Spearman=0.2806\n",
      "----------------------------------------------------------\n",
      "Epoch 13/200, Step 1/105, Loss: 0.1930\n",
      "Epoch 13/200 -- Train Loss: 0.1623 , Validation Loss: 0.1271\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.1260, RMSE=0.3549, MAE=0.2909, R^2=-1.1467, Pearson=0.3869, Spearman=0.3825\n",
      "Label 2: MSE=0.1270, RMSE=0.3564, MAE=0.2991, R^2=-2.5563, Pearson=0.2434, Spearman=0.2514\n",
      "Overall (Flattened): MSE=0.1265, RMSE=0.3557, MAE=0.2950, R^2=-1.5749, Pearson=0.3610, Spearman=0.3506\n",
      "----------------------------------------------------------\n",
      "Epoch 14/200, Step 1/105, Loss: 0.1645\n",
      "Epoch 14/200 -- Train Loss: 0.1661 , Validation Loss: 0.0724\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0638, RMSE=0.2526, MAE=0.2045, R^2=-0.0877, Pearson=0.4670, Spearman=0.4259\n",
      "Label 2: MSE=0.0808, RMSE=0.2842, MAE=0.2342, R^2=-1.2611, Pearson=0.3041, Spearman=0.3028\n",
      "Overall (Flattened): MSE=0.0723, RMSE=0.2689, MAE=0.2193, R^2=-0.4716, Pearson=0.3802, Spearman=0.3439\n",
      "----------------------------------------------------------\n",
      "Epoch 15/200, Step 1/105, Loss: 0.1271\n",
      "Epoch 15/200 -- Train Loss: 0.1516 , Validation Loss: 0.0622\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0620, RMSE=0.2489, MAE=0.1953, R^2=-0.0560, Pearson=0.4738, Spearman=0.4379\n",
      "Label 2: MSE=0.0633, RMSE=0.2517, MAE=0.1997, R^2=-0.7732, Pearson=0.1755, Spearman=0.1734\n",
      "Overall (Flattened): MSE=0.0627, RMSE=0.2503, MAE=0.1975, R^2=-0.2753, Pearson=0.3633, Spearman=0.3114\n",
      "----------------------------------------------------------\n",
      "Epoch 16/200, Step 1/105, Loss: 0.1327\n",
      "Epoch 16/200 -- Train Loss: 0.1538 , Validation Loss: 0.0538\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0576, RMSE=0.2401, MAE=0.1925, R^2=0.0179, Pearson=0.4775, Spearman=0.4400\n",
      "Label 2: MSE=0.0499, RMSE=0.2233, MAE=0.1795, R^2=-0.3962, Pearson=0.2778, Spearman=0.2766\n",
      "Overall (Flattened): MSE=0.0538, RMSE=0.2318, MAE=0.1860, R^2=-0.0941, Pearson=0.4060, Spearman=0.3646\n",
      "----------------------------------------------------------\n",
      "Epoch 17/200, Step 1/105, Loss: 0.1386\n",
      "Epoch 17/200 -- Train Loss: 0.1561 , Validation Loss: 0.0853\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0816, RMSE=0.2857, MAE=0.2319, R^2=-0.3911, Pearson=0.3577, Spearman=0.3924\n",
      "Label 2: MSE=0.0892, RMSE=0.2986, MAE=0.2513, R^2=-1.4960, Pearson=0.1304, Spearman=0.1535\n",
      "Overall (Flattened): MSE=0.0854, RMSE=0.2922, MAE=0.2416, R^2=-0.7382, Pearson=0.3107, Spearman=0.3027\n",
      "----------------------------------------------------------\n",
      "Epoch 18/200, Step 1/105, Loss: 0.1315\n",
      "Epoch 18/200 -- Train Loss: 0.1566 , Validation Loss: 0.0549\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0644, RMSE=0.2537, MAE=0.2027, R^2=-0.0972, Pearson=0.4269, Spearman=0.3950\n",
      "Label 2: MSE=0.0444, RMSE=0.2108, MAE=0.1664, R^2=-0.2441, Pearson=0.2922, Spearman=0.2796\n",
      "Overall (Flattened): MSE=0.0544, RMSE=0.2333, MAE=0.1845, R^2=-0.1075, Pearson=0.4100, Spearman=0.3587\n",
      "----------------------------------------------------------\n",
      "Epoch 19/200, Step 1/105, Loss: 0.1453\n",
      "Epoch 19/200 -- Train Loss: 0.1516 , Validation Loss: 0.1791\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.2040, RMSE=0.4516, MAE=0.3800, R^2=-2.4759, Pearson=0.2371, Spearman=0.1951\n",
      "Label 2: MSE=0.1559, RMSE=0.3948, MAE=0.3223, R^2=-3.3641, Pearson=0.1331, Spearman=0.1224\n",
      "Overall (Flattened): MSE=0.1799, RMSE=0.4242, MAE=0.3512, R^2=-2.6623, Pearson=0.2246, Spearman=0.1709\n",
      "----------------------------------------------------------\n",
      "Epoch 20/200, Step 1/105, Loss: 0.1898\n",
      "Epoch 20/200 -- Train Loss: 0.1551 , Validation Loss: 0.1081\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.1047, RMSE=0.3236, MAE=0.2690, R^2=-0.7850, Pearson=0.5607, Spearman=0.5450\n",
      "Label 2: MSE=0.1106, RMSE=0.3325, MAE=0.2705, R^2=-2.0957, Pearson=0.2904, Spearman=0.2866\n",
      "Overall (Flattened): MSE=0.1077, RMSE=0.3281, MAE=0.2698, R^2=-1.1914, Pearson=0.4717, Spearman=0.4357\n",
      "----------------------------------------------------------\n",
      "Epoch 21/200, Step 1/105, Loss: 0.2356\n",
      "Epoch 21/200 -- Train Loss: 0.1384 , Validation Loss: 0.0568\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0527, RMSE=0.2295, MAE=0.1827, R^2=0.1020, Pearson=0.4730, Spearman=0.4273\n",
      "Label 2: MSE=0.0605, RMSE=0.2460, MAE=0.1969, R^2=-0.6941, Pearson=0.3185, Spearman=0.2955\n",
      "Overall (Flattened): MSE=0.0566, RMSE=0.2379, MAE=0.1898, R^2=-0.1521, Pearson=0.3619, Spearman=0.3018\n",
      "----------------------------------------------------------\n",
      "Epoch 22/200, Step 1/105, Loss: 0.2284\n",
      "Epoch 22/200 -- Train Loss: 0.1504 , Validation Loss: 0.0720\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0713, RMSE=0.2670, MAE=0.2145, R^2=-0.2150, Pearson=0.5618, Spearman=0.5387\n",
      "Label 2: MSE=0.0715, RMSE=0.2674, MAE=0.2183, R^2=-1.0020, Pearson=0.3030, Spearman=0.2930\n",
      "Overall (Flattened): MSE=0.0714, RMSE=0.2672, MAE=0.2164, R^2=-0.4534, Pearson=0.4864, Spearman=0.4367\n",
      "----------------------------------------------------------\n",
      "Epoch 23/200, Step 1/105, Loss: 0.1124\n",
      "Epoch 23/200 -- Train Loss: 0.1462 , Validation Loss: 0.1829\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.2135, RMSE=0.4621, MAE=0.3848, R^2=-2.6385, Pearson=0.3267, Spearman=0.2939\n",
      "Label 2: MSE=0.1508, RMSE=0.3884, MAE=0.3220, R^2=-3.2225, Pearson=0.0887, Spearman=0.0850\n",
      "Overall (Flattened): MSE=0.1822, RMSE=0.4268, MAE=0.3534, R^2=-2.7079, Pearson=0.2358, Spearman=0.1925\n",
      "----------------------------------------------------------\n",
      "Epoch 24/200, Step 1/105, Loss: 0.3392\n",
      "Epoch 24/200 -- Train Loss: 0.1688 , Validation Loss: 0.1144\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0805, RMSE=0.2837, MAE=0.2269, R^2=-0.3714, Pearson=0.5120, Spearman=0.4802\n",
      "Label 2: MSE=0.1459, RMSE=0.3819, MAE=0.3169, R^2=-3.0830, Pearson=0.1963, Spearman=0.1898\n",
      "Overall (Flattened): MSE=0.1132, RMSE=0.3364, MAE=0.2719, R^2=-1.3033, Pearson=0.4221, Spearman=0.3660\n",
      "----------------------------------------------------------\n",
      "Early stopping triggered at epoch 24\n",
      "Finished Training!\n",
      "Best Pearson Correlation is 0.4863580218852038 at epoch 21\n",
      "Best R2 Square Correlation is -0.09411622792481844 at epoch 15\n",
      "\n",
      "\n",
      "*** Deleting model paths ***\n",
      "Evaluating model at best_r2 epoch: 15\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0585, RMSE=0.2419, MAE=0.1910, R^2=0.0037, Pearson=0.4810, Spearman=0.4471\n",
      "Label 2: MSE=0.0539, RMSE=0.2321, MAE=0.1839, R^2=-0.4285, Pearson=0.2399, Spearman=0.2374\n",
      "Overall (Flattened): MSE=0.0562, RMSE=0.2371, MAE=0.1874, R^2=-0.1080, Pearson=0.3930, Spearman=0.3482\n",
      "----------------------------------------------------------\n",
      "Model at best_r2 epoch 15 is saved as best_r2_model\n",
      "Evaluating model at best_pearson epoch: 21\n",
      "------------------------Evaluation------------------------\n",
      "Label 1: MSE=0.0756, RMSE=0.2750, MAE=0.2239, R^2=-0.2876, Pearson=0.5869, Spearman=0.5399\n",
      "Label 2: MSE=0.0762, RMSE=0.2761, MAE=0.2267, R^2=-1.0204, Pearson=0.3072, Spearman=0.3122\n",
      "Overall (Flattened): MSE=0.0759, RMSE=0.2755, MAE=0.2253, R^2=-0.4967, Pearson=0.5059, Spearman=0.4463\n",
      "----------------------------------------------------------\n",
      "Model at best_pearson epoch 21 is saved as best_pearson_model\n",
      "All contents in /pmglocal/ty2514/Enhancer/Enhancer/data/ConvNetDeep_G+G- have been deleted as save_model is set to False.\n",
      "R_square values saved to /pmglocal/ty2514/Enhancer/Enhancer/data/ConvNetDeep_G+G-/ConvNetDeep_G+G-_Metrics.csv\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "import os\n",
    "df = pd.read_csv('/pmglocal/ty2514/Enhancer/Enhancer/data/filtered_input_data.csv')\n",
    "target_labels = [\"GFP+\",\"GFP-\"]\n",
    "\n",
    "# Initialize the R_square list\n",
    "seed_list = []\n",
    "batch_list = []\n",
    "lr_list = []\n",
    "dropout_list = []\n",
    "\n",
    "mse_list_p = []\n",
    "rmse_list_p = []\n",
    "mae_list_p = []\n",
    "r2_list_p = []\n",
    "pearson_corr_list_p = []\n",
    "spearman_corr_list_p = []\n",
    "\n",
    "mse_list_r = []\n",
    "rmse_list_r = []\n",
    "mae_list_r = []\n",
    "r2_list_r = []\n",
    "pearson_corr_list_r = []\n",
    "spearman_corr_list_r = []\n",
    "\n",
    "best_pearson_epochs = []\n",
    "best_r2_epochs = []\n",
    "\n",
    "batches = [96]\n",
    "seeds = [9]\n",
    "learning_rates = [5e-3]\n",
    "\n",
    "output_dir = '/pmglocal/ty2514/Enhancer/Enhancer/data/ConvNetDeep_G+G-'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "# Save the R_square results to a CSV file\n",
    "filename = os.path.join(output_dir, 'ConvNetDeep_G+G-_Metrics.csv')\n",
    "\n",
    "# Split the dataset\n",
    "for seed in seeds: \n",
    "    for batch in batches:\n",
    "        train_df, val_df, test_df = split_dataset(df, split_type='random', split_pattern=[0.7, 0.15, 0.15], seed=seed)\n",
    "\n",
    "        # Process datasets\n",
    "        train = EnhancerDatasetWithID(train_df, feature_list=['G+','G-'], scale_mode='none')\n",
    "        val = EnhancerDatasetWithID(val_df, feature_list=['G+','G-'], scale_mode='none')\n",
    "        test = EnhancerDatasetWithID(test_df, feature_list=['G+','G-'], scale_mode='none')\n",
    "\n",
    "        # DataLoader setup\n",
    "        train_loader = DataLoader(dataset=train, batch_size=batch, shuffle=True)\n",
    "        val_loader = DataLoader(dataset=val, batch_size=batch, shuffle=False)\n",
    "        test_loader = DataLoader(dataset=test, batch_size=batch, shuffle=False)\n",
    "\n",
    "        # Hyperparameter search\n",
    "        for dropout in [0.3]:\n",
    "            # Model setup\n",
    "            input_model = ConvNetDeep(num_classes=2, drop_out=dropout)\n",
    "            for learning_rate in learning_rates:\n",
    "                formatted_lr = \"{:.5f}\".format(learning_rate)\n",
    "                print(f\"dropout{dropout}_ba{batch}_lr{formatted_lr}_seed{seed}\")\n",
    "\n",
    "                _, _, model, train_losses_by_batch, test_losses_by_batch, results, best_pearson_epoch, best_r2_epoch,  pearson_metrics, r2_metrics, device  = train_model(\n",
    "                    input_model, train_loader, val_loader, test_loader,target_labels=target_labels, num_epochs=200, batch_size=batch, learning_rate=learning_rate, \n",
    "                    criteria='mse',optimizer_type = \"adam\", patience=15, seed = seed, save_model= False, dir_path=output_dir)\n",
    "                \n",
    "                # Saving all metrics for best r2 model and pearson model respectively\n",
    "                mse_list_p.append(pearson_metrics['mse'][-1])\n",
    "                rmse_list_p.append(pearson_metrics['rmse'][-1])\n",
    "                mae_list_p.append(pearson_metrics['mae'][-1])\n",
    "                r2_list_p.append(pearson_metrics['r2'][-1])\n",
    "                pearson_corr_list_p.append(pearson_metrics['pearson_corr'][-1])\n",
    "                spearman_corr_list_p.append(pearson_metrics['spearman_corr'][-1])\n",
    "                \n",
    "                mse_list_r.append(r2_metrics['mse'][-1])\n",
    "                rmse_list_r.append(r2_metrics['rmse'][-1])\n",
    "                mae_list_r.append(r2_metrics['mae'][-1])\n",
    "                r2_list_r.append(r2_metrics['r2'][-1])\n",
    "                pearson_corr_list_r.append(r2_metrics['pearson_corr'][-1])\n",
    "                spearman_corr_list_r.append(r2_metrics['spearman_corr'][-1])\n",
    "\n",
    "                seed_list.append(seed)\n",
    "                batch_list.append(batch)\n",
    "                lr_list.append(formatted_lr)\n",
    "                dropout_list.append(dropout)\n",
    "                best_pearson_epochs.append(best_pearson_epoch)\n",
    "                best_r2_epochs.append(best_r2_epoch)\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    \"batch\": batch_list,\n",
    "    \"lr\": lr_list,\n",
    "    \"drop_out\": dropout_list,\n",
    "    \"seed\": seed_list,\n",
    "    \"mse_p\":mse_list_p,\n",
    "    \"rmse_p\":rmse_list_p,\n",
    "    \"mae_p\":mae_list_p,\n",
    "    \"r2_p\":r2_list_p,\n",
    "    \"pearson_corr_p\":pearson_corr_list_p,\n",
    "    \"spearman_corr_p\":spearman_corr_list_p,\n",
    "    \"mse_r\":mse_list_r,\n",
    "    \"rmse_r\":rmse_list_r,\n",
    "    \"mae_r\":mae_list_r,\n",
    "    \"r2_r\":r2_list_r,\n",
    "    \"pearson_corr_r\":pearson_corr_list_r,\n",
    "    \"spearman_corr_r\":spearman_corr_list_r,\n",
    "    \"best_pearson_epoch\": best_pearson_epochs,\n",
    "    \"best_r2_epoch\": best_r2_epochs\n",
    "})\n",
    "results_df.to_csv(filename, index=False)\n",
    "print(f\"R_square values saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = glob.glob('/pmglocal/ty2514/Enhancer/Enhancer/data/ExplaiNN_GFP_70NN/best_r2*.pth')\n",
    "\n",
    "# Function to evaluate the model with a specific set of weights\n",
    "def evaluate_model_with_weights(model, test_loader, weight_file):\n",
    "    # Load the saved weights\n",
    "    model.load_state_dict(torch.load(weight_file))\n",
    "    \n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    all_fragment_ids = []\n",
    "\n",
    "    # Disable gradient calculation for inference\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs, labels, fragment_ids = data  # Get inputs, labels, and fragment IDs\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Get predictions\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Store predictions, true labels, and fragment IDs\n",
    "            all_predictions.append(outputs.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "            all_fragment_ids.append(fragment_ids)  # Keep track of the sample IDs\n",
    "\n",
    "    # Convert lists of numpy arrays into a single numpy array\n",
    "    all_predictions = np.concatenate(all_predictions, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "    all_fragment_ids = np.concatenate(all_fragment_ids, axis=0)\n",
    "    \n",
    "    return all_predictions, all_labels, all_fragment_ids\n",
    "\n",
    "# Loop over each weight file and evaluate the model\n",
    "for weight_file in file_list:\n",
    "    print(f\"Evaluating model with weights from: {weight_file}\")\n",
    "    \n",
    "    # Call the evaluation function\n",
    "    predictions, labels, fragment_ids = evaluate_model_with_weights(input_model, test_loader, weight_file)\n",
    "    \n",
    "    # Print or save results\n",
    "    df_predictions = pd.DataFrame({\n",
    "        'Fragment_ID': fragment_ids,  # Add the fragment IDs\n",
    "        'Predictions': predictions.flatten(),  # Assuming 1D output\n",
    "        'True Labels': labels.flatten()\n",
    "    })\n",
    "    \n",
    "    # Save results to a CSV file\n",
    "    output_file = f'/pmglocal/ty2514/Enhancer/Enhancer/data/ExplaiNN_GFP_70NN/prediction_results.csv'\n",
    "    df_predictions.to_csv(output_file, index=False)\n",
    "    print(f\"Results saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train ExplaiNN Predict GFP+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to save the result\n",
    "seed = 42\n",
    "batch = 168\n",
    "num_cnns = 90\n",
    "learning_rate= 5e-5\n",
    "target_labels = [\"GFP+\"]\n",
    "output_dir = '/pmglocal/ty2514/Enhancer/Enhancer/data/ExplaiNN_GFP+_90NN'\n",
    "\n",
    "df = pd.read_csv('/pmglocal/ty2514/Enhancer/Enhancer/data/input_data.csv')\n",
    "\n",
    "input_model = ExplaiNN3(num_cnns = num_cnns, input_length = 608, num_classes = 1, \n",
    "                 filter_size = 19, num_fc=2, pool_size=7, pool_stride=7, \n",
    "                 drop_out = 0.3, weight_path = None)# Training\n",
    "\n",
    "_, _, model, train_losses_by_batch, test_losses_by_batch, results, best_pearson_epoch, best_r2_epoch, device  = train_model(input_model, train_loader, test_loader, target_labels=target_labels,\n",
    "                                                                                                                            num_epochs=200, \n",
    "                                                                                         batch_size=batch, learning_rate=learning_rate, \n",
    "                                                                                         criteria='mse',optimizer_type = \"adam\", patience=15, \n",
    "                                                                                         seed = seed, save_model= True, dir_path=output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = glob.glob('/pmglocal/ty2514/Enhancer/Enhancer/data/ExplaiNN_GFP+_90NN/best_r2*.pth')\n",
    "\n",
    "# Function to evaluate the model with a specific set of weights\n",
    "def evaluate_model_with_weights(model, test_loader, weight_file):\n",
    "    # Load the saved weights\n",
    "    model.load_state_dict(torch.load(weight_file))\n",
    "    \n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    all_fragment_ids = []\n",
    "\n",
    "    # Disable gradient calculation for inference\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs, labels, fragment_ids = data  # Get inputs, labels, and fragment IDs\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Get predictions\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Store predictions, true labels, and fragment IDs\n",
    "            all_predictions.append(outputs.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "            all_fragment_ids.append(fragment_ids)  # Keep track of the sample IDs\n",
    "\n",
    "    # Convert lists of numpy arrays into a single numpy array\n",
    "    all_predictions = np.concatenate(all_predictions, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "    all_fragment_ids = np.concatenate(all_fragment_ids, axis=0)\n",
    "    \n",
    "    return all_predictions, all_labels, all_fragment_ids\n",
    "\n",
    "# Loop over each weight file and evaluate the model\n",
    "for weight_file in file_list:\n",
    "    print(f\"Evaluating model with weights from: {weight_file}\")\n",
    "    \n",
    "    # Call the evaluation function\n",
    "    predictions, labels, fragment_ids = evaluate_model_with_weights(input_model, test_loader, weight_file)\n",
    "    \n",
    "    # Print or save results\n",
    "    df_predictions = pd.DataFrame({\n",
    "        'Fragment_ID': fragment_ids,  # Add the fragment IDs\n",
    "        'Predictions': predictions.flatten(),  # Assuming 1D output\n",
    "        'True Labels': labels.flatten()\n",
    "    })\n",
    "    \n",
    "    # Save results to a CSV file\n",
    "    output_file = f'/pmglocal/ty2514/Enhancer/Enhancer/data/ExplaiNN_GFP+_90NN/prediction_results.csv'\n",
    "    df_predictions.to_csv(output_file, index=False)\n",
    "    print(f\"Results saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train DeepSTARR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to save the result\n",
    "seed = 42\n",
    "batch = 168\n",
    "learning_rate= 5e-5\n",
    "target_labels = [\"GFP\"]\n",
    "output_dir = '/pmglocal/ty2514/Enhancer/Enhancer/data/DeepSTARR_GFP'\n",
    "\n",
    "\n",
    "input_model = DeepSTARR(num_classes = 1)\n",
    "\n",
    "_, _, model_deepstarr, train_losses_by_batch, test_losses_by_batch, results, best_pearson_epoch, best_r2_epoch, device  = train_model(input_model, train_loader, test_loader, target_labels=target_labels,\n",
    "                                                                                                                            num_epochs=200, \n",
    "                                                                                         batch_size=batch, learning_rate=learning_rate, \n",
    "                                                                                         criteria='mse',optimizer_type = \"adam\", patience=15, \n",
    "                                                                                         seed = seed, save_model= True, dir_path=output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = glob.glob('/pmglocal/ty2514/Enhancer/Enhancer/data/DeepSTARR_GFP/best_r2*.pth')\n",
    "\n",
    "for weight_file in file_list:\n",
    "    print(f\"Evaluating model with weights from: {weight_file}\")\n",
    "    \n",
    "    # Call the evaluation function\n",
    "    predictions_d, labels_d, fragment_ids_d = evaluate_model_with_weights(input_model, test_loader, weight_file)\n",
    "    \n",
    "    # Print or save results\n",
    "    df_predictions_d = pd.DataFrame({\n",
    "        'Fragment_ID': fragment_ids_d,  # Add the fragment IDs\n",
    "        'Predictions': predictions_d.flatten(),  # Assuming 1D output\n",
    "        'True Labels': labels_d.flatten()\n",
    "    })\n",
    "    \n",
    "    # Save results to a CSV file\n",
    "    #output_file = f'/pmglocal/ty2514/Enhancer/Enhancer/data/ExplaiNN_GFP_70NN/prediction_results.csv'\n",
    "    #df_predictions.to_csv(output_file, index=False)\n",
    "    #print(f\"Results saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Ensure that the DataFrames are aligned by index (if necessary)\n",
    "# For example, you can merge them if they have different indices:\n",
    "# combined_df = pd.merge(df_predictions_d[['Predictions']], df_predictions[['Predictions']], left_index=True, right_index=True, suffixes=('_model1', '_model2'))\n",
    "\n",
    "# Create a scatter plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=df_predictions_d['Predictions'], y=df_predictions['Predictions'])\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Predictions from Model 1')\n",
    "plt.ylabel('Predictions from Model 2')\n",
    "plt.title('Correlation between Predictions of Model 1 and Model 2')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "explainn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
